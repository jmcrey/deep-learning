{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.17272232 -0.06402743 -0.13467415 -0.01027226  0.01422262  0.06318235\n",
      "  -0.02004334  0.00417023]]\n",
      "test std = \n",
      "[[0.97501882 1.12457975 1.06447313 0.93029679 1.0017629  0.9233102\n",
      "  1.06444755 1.06905814]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[ 2.09165346, -1.15889146,  0.23369685, -1.27540799, -0.69073359,\n",
       "          -0.22677074, -0.52816416,  0.15214607,  1.        ]]),\n",
       " 1.0,\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,d = x_train.shape\n",
    "lam = 1E-6\n",
    "xi = x_train[0, :] # 1-by-d matrix\n",
    "yi = float(y_train[0, :]) # scalar\n",
    "w = numpy.zeros((d, 1))\n",
    "xi, yi, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6931471805599453,\n",
       " matrix([[-1.04582673],\n",
       "         [ 0.57944573],\n",
       "         [-0.11684842],\n",
       "         [ 0.63770399],\n",
       "         [ 0.3453668 ],\n",
       "         [ 0.11338537],\n",
       "         [ 0.26408208],\n",
       "         [-0.07607304],\n",
       "         [-0.5       ]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochastic_objective_gradient(w, xi, yi, lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[ 2.09165346, -1.15889146,  0.23369685, -1.27540799, -0.69073359,\n",
       "          -0.22677074, -0.52816416,  0.15214607,  1.        ]]),\n",
       " 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yx = yi * xi # 1-by-d matrix\n",
    "yxw = float(numpy.dot(yx, w)) # scalar\n",
    "yx, yxw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6931471805599453, 0.0, 0.6931471805599453)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "obj = loss + reg\n",
    "loss, reg, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 1 / (1 + numpy.exp(yxw))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(matrix([[-1.04582673],\n",
       "         [ 0.57944573],\n",
       "         [-0.11684842],\n",
       "         [ 0.63770399],\n",
       "         [ 0.3453668 ],\n",
       "         [ 0.11338537],\n",
       "         [ 0.26408208],\n",
       "         [-0.07607304],\n",
       "         [-0.5       ]]),\n",
       " matrix([[-1.04582673],\n",
       "         [ 0.57944573],\n",
       "         [-0.11684842],\n",
       "         [ 0.63770399],\n",
       "         [ 0.3453668 ],\n",
       "         [ 0.11338537],\n",
       "         [ 0.26408208],\n",
       "         [-0.07607304],\n",
       "         [-0.5       ]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "g_loss_2 = z * -yx.T\n",
    "g = g_loss + lam * w # d-by-1 matrix\n",
    "print(numpy.array_equal(g_loss, g_loss_2))\n",
    "g_loss, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6931471805599453,\n",
       " array([[-0.02494749],\n",
       "        [ 0.43858289],\n",
       "        [ 0.03665312],\n",
       "        [ 0.18755359],\n",
       "        [ 0.22536851],\n",
       "        [ 0.1963183 ],\n",
       "        [ 0.20493193],\n",
       "        [ 0.22275409],\n",
       "        [-0.375     ]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objvals = numpy.zeros(8)\n",
    "mat = numpy.zeros((8,9))\n",
    "for i in range(8):\n",
    "    n,d = x_train.shape\n",
    "    lam = 1E-6\n",
    "    xi = x_train[i, :] # 1-by-d matrix\n",
    "    yi = float(y_train[i, :]) # scalar\n",
    "    w = numpy.zeros((d, 1))\n",
    "    obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "    objvals[i] = obj\n",
    "    mat[i, :] = g.T\n",
    "objavg = numpy.average(objvals)\n",
    "w_star = numpy.average(mat, axis=0).reshape((9,1))\n",
    "objavg, w_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of stochastic_objective_gradient\n",
    "    # Use matrix-vector multiplication; do not use FOR LOOP of vector-vector multiplications\n",
    "    n,d = xi.shape\n",
    "    yx = numpy.multiply(yi, xi)  # b by d matrix\n",
    "    yxw = numpy.dot(yx, w)  # b x 1 vector\n",
    "\n",
    "    # Solve objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # b x 1 vector\n",
    "    reg = (lam / 2) * numpy.sum(w * w)  # scalar\n",
    "    obj = numpy.average(loss + reg)  # scalar\n",
    "\n",
    "    # Calculate gradient\n",
    "    z = (1 / (1 + numpy.exp(yxw)))\n",
    "    g_loss = numpy.multiply(z, -yx)\n",
    "    reg_loss = g_loss.T + (lam * w) # d x n matrix\n",
    "    g = numpy.average(reg_loss, axis=1) # d x 1 vector\n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "b = 8\n",
    "xi = x_train[0:b, :]\n",
    "yi = y_train[0:b].reshape((b, 1))\n",
    "w = numpy.zeros((d,1))\n",
    "obj, g = mb_stochastic_objective_gradient(w, xi, yi, lam, b)\n",
    "obj == objavg, numpy.array_equal(g, w_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[-0.02494749],\n",
       "         [ 0.43858289],\n",
       "         [ 0.03665312],\n",
       "         [ 0.18755359],\n",
       "         [ 0.22536851],\n",
       "         [ 0.1963183 ],\n",
       "         [ 0.20493193],\n",
       "         [ 0.22275409],\n",
       "         [-0.375     ]]),\n",
       " True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj, g = mb_stochastic_objective_gradient(w, xi, yi, lam, b)\n",
    "g, numpy.array_equal(g, avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[ 2.09165346, -1.15889146,  0.23369685, -1.27540799, -0.69073359,\n",
       "          -0.22677074, -0.52816416,  0.15214607,  1.        ],\n",
       "         [-0.57558673,  0.63247704, -0.60362146,  0.83331307,  0.42101948,\n",
       "          -0.81608078,  0.69018075, -0.79489933,  1.        ],\n",
       "         [ 0.31349334,  0.0246913 ,  0.86168558, -1.27540799, -0.69073359,\n",
       "           0.35000092, -0.55869912, -0.020044  ,  1.        ],\n",
       "         [-0.57558673, -0.9349704 , -0.91761582, -1.27540799, -0.69073359,\n",
       "          -0.22677074, -1.01367003, -0.9670894 ,  1.        ],\n",
       "         [ 0.01713331, -0.35917338,  0.33836164, -0.03498384,  0.17782349,\n",
       "          -0.43992543, -1.08390044, -0.53661422,  1.        ],\n",
       "         [-0.01713331, -2.00799213, -0.44302642, -1.14341911, -1.71516953,\n",
       "          -0.63838656,  0.63809002,  0.19223407, -1.        ],\n",
       "         [-0.57558673, -1.70269976,  0.02436727,  0.70927065, -0.11748592,\n",
       "          -0.86623482, -0.87320921, -0.70880429,  1.        ],\n",
       "         [-0.27922671, -1.51076742, -0.08029752,  0.46118582, -0.2998829 ,\n",
       "          -0.27692466, -0.54953863, -0.88099437,  1.        ]]),\n",
       " matrix([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yx = numpy.multiply(yi, xi)\n",
    "yxw = numpy.dot(yx, w)\n",
    "yx, yxw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0.69314718],\n",
       "         [0.69314718],\n",
       "         [0.69314718],\n",
       "         [0.69314718],\n",
       "         [0.69314718],\n",
       "         [0.69314718],\n",
       "         [0.69314718],\n",
       "         [0.69314718]]),\n",
       " 0.0,\n",
       " 0.6931471805599453)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = numpy.log(1 + numpy.exp(-yxw))\n",
    "reg = lam / 2 * numpy.sum(w * w)\n",
    "obj = numpy.average(loss + reg)  # scalar\n",
    "loss, reg, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        [0.5]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 1 / (1 + numpy.exp(yxw))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1.04582673,  0.57944573, -0.11684842,  0.63770399,  0.3453668 ,\n",
       "          0.11338537,  0.26408208, -0.07607304, -0.5       ],\n",
       "        [ 0.28779336, -0.31623852,  0.30181073, -0.41665653, -0.21050974,\n",
       "          0.40804039, -0.34509038,  0.39744967, -0.5       ],\n",
       "        [-0.15674667, -0.01234565, -0.43084279,  0.63770399,  0.3453668 ,\n",
       "         -0.17500046,  0.27934956,  0.010022  , -0.5       ],\n",
       "        [ 0.28779336,  0.4674852 ,  0.45880791,  0.63770399,  0.3453668 ,\n",
       "          0.11338537,  0.50683501,  0.4835447 , -0.5       ],\n",
       "        [-0.00856666,  0.17958669, -0.16918082,  0.01749192, -0.08891175,\n",
       "          0.21996272,  0.54195022,  0.26830711, -0.5       ],\n",
       "        [ 0.00856666,  1.00399607,  0.22151321,  0.57170955,  0.85758477,\n",
       "          0.31919328, -0.31904501, -0.09611704,  0.5       ],\n",
       "        [ 0.28779336,  0.85134988, -0.01218364, -0.35463533,  0.05874296,\n",
       "          0.43311741,  0.43660461,  0.35440215, -0.5       ],\n",
       "        [ 0.13961335,  0.75538371,  0.04014876, -0.23059291,  0.14994145,\n",
       "          0.13846233,  0.27476932,  0.44049718, -0.5       ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss = numpy.multiply(z, -yx)\n",
    "g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_loss = g_loss.T + lam * w\n",
    "numpy.array_equal(g_loss.T, mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[-0.02494749],\n",
       "         [ 0.43858289],\n",
       "         [ 0.03665312],\n",
       "         [ 0.18755359],\n",
       "         [ 0.22536851],\n",
       "         [ 0.1963183 ],\n",
       "         [ 0.20493193],\n",
       "         [ 0.22275409],\n",
       "         [-0.375     ]]),\n",
       " 0.0248837325)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = numpy.average(g_loss, axis=1)\n",
    "g1 = (-0.42018124,  0.02528976,  0.17378009,  0.27169091, -0.12320057, -0.02528976,  0.47076076, -0.17378009)\n",
    "g1 = sum(g1) / 8\n",
    "g, g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8\n",
      "8\n",
      "8 16\n",
      "8\n",
      "16 24\n",
      "8\n",
      "24 32\n",
      "8\n",
      "32 40\n",
      "8\n",
      "40 48\n",
      "8\n",
      "48 56\n",
      "8\n",
      "56 64\n",
      "8\n",
      "64 72\n",
      "8\n",
      "72 80\n",
      "8\n",
      "80 88\n",
      "8\n",
      "88 96\n",
      "8\n",
      "96 104\n",
      "8\n",
      "104 112\n",
      "8\n",
      "112 120\n",
      "8\n",
      "120 128\n",
      "8\n",
      "128 136\n",
      "8\n",
      "136 144\n",
      "8\n",
      "144 152\n",
      "8\n",
      "152 160\n",
      "8\n",
      "160 168\n",
      "8\n",
      "168 176\n",
      "8\n",
      "176 184\n",
      "8\n",
      "184 192\n",
      "8\n",
      "192 200\n",
      "8\n",
      "200 208\n",
      "8\n",
      "208 216\n",
      "8\n",
      "216 224\n",
      "8\n",
      "224 232\n",
      "8\n",
      "232 240\n",
      "8\n",
      "240 248\n",
      "8\n",
      "248 256\n",
      "8\n",
      "256 264\n",
      "8\n",
      "264 272\n",
      "8\n",
      "272 280\n",
      "8\n",
      "280 288\n",
      "8\n",
      "288 296\n",
      "8\n",
      "296 304\n",
      "8\n",
      "304 312\n",
      "8\n",
      "312 320\n",
      "8\n",
      "320 328\n",
      "8\n",
      "328 336\n",
      "8\n",
      "336 344\n",
      "8\n",
      "344 352\n",
      "8\n",
      "352 360\n",
      "8\n",
      "360 368\n",
      "8\n",
      "368 376\n",
      "8\n",
      "376 384\n",
      "8\n",
      "384 392\n",
      "8\n",
      "392 400\n",
      "8\n",
      "400 408\n",
      "8\n",
      "408 416\n",
      "8\n",
      "416 424\n",
      "8\n",
      "424 432\n",
      "8\n",
      "432 440\n",
      "8\n",
      "440 448\n",
      "8\n",
      "448 456\n",
      "8\n",
      "456 464\n",
      "8\n",
      "464 472\n",
      "8\n",
      "472 480\n",
      "8\n",
      "480 488\n",
      "8\n",
      "488 496\n",
      "8\n",
      "496 504\n",
      "8\n",
      "504 512\n",
      "8\n",
      "512 520\n",
      "8\n",
      "520 528\n",
      "8\n",
      "528 536\n",
      "8\n",
      "536 544\n",
      "8\n",
      "544 552\n",
      "8\n",
      "552 560\n",
      "8\n",
      "560 568\n",
      "8\n",
      "568 576\n",
      "8\n",
      "576 584\n",
      "8\n",
      "584 592\n",
      "8\n",
      "592 600\n",
      "8\n",
      "600 608\n",
      "8\n",
      "608 616\n",
      "8\n",
      "616 624\n",
      "8\n",
      "624 632\n",
      "8\n",
      "632 640\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "iters = int(n / b)\n",
    "start = 0\n",
    "for i in range(iters):\n",
    "    end = start + b\n",
    "    print(start, end)\n",
    "    xi = x[rand_indices[0:b], :]\n",
    "    print(len(xi))\n",
    "    yi = y[rand_indices[0:b]].reshape((b, 1))\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
