{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HM2: Numerical Optimization for Logistic Regression.\n",
    "\n",
    "### Name: Jeremiah McReynolds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read the lecture note: [click here](https://github.com/wangshusen/DeepLearning/blob/master/LectureNotes/Logistic/paper/logistic.pdf)\n",
    "\n",
    "2. Read, complete, and run my code.\n",
    "\n",
    "3. **Implement mini-batch SGD** and evaluate the performance.\n",
    "\n",
    "4. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain **the code** and **the output after execution**.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "5. Upload this .HTML file to your Google Drive, Dropbox, or your Github repo.  (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "6. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM2/HM2.html\n",
    "\n",
    "\n",
    "## Grading criteria:\n",
    "\n",
    "1. When computing the ```gradient``` and ```objective function value``` using a batch of samples, use **matrix-vector multiplication** rather than a FOR LOOP of **vector-vector multiplications**.\n",
    "\n",
    "2. Plot ```objective function value``` against ```epochs```. In the plot, compare GD, SGD, and MB-SGD (with $b=8$ and $b=64$). The plot must look reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (768, 8)\n",
      "Shape of y: (768,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes')\n",
    "x = x_sparse.todense()\n",
    "\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 8)\n",
      "Shape of x_test: (128, 8)\n",
      "Shape of y_train: (640, 1)\n",
      "Shape of y_test: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = 640\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = numpy.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices].reshape(n_train, 1)\n",
    "y_test = y[test_indices].reshape(n_test, 1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean = \n",
      "[[-0.08880541  0.00246106  0.12585071  0.13527958  0.00222387  0.09052786\n",
      "  -0.03670071  0.03305912]]\n",
      "test std = \n",
      "[[0.94527664 0.9179219  0.95019601 0.98456125 0.92215021 0.94298993\n",
      "  0.97641536 1.03921168]]\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "import numpy\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = numpy.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = numpy.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / (sig + 1E-6)\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / (sig + 1E-6)\n",
    "\n",
    "print('test mean = ')\n",
    "print(numpy.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(numpy.std(x_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Add a dimension of all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (640, 9)\n",
      "Shape of x_test: (128, 9)\n"
     ]
    }
   ],
   "source": [
    "n_train, d = x_train.shape\n",
    "x_train = numpy.concatenate((x_train, numpy.ones((n_train, 1))), axis=1)\n",
    "\n",
    "n_test, d = x_test.shape\n",
    "x_test = numpy.concatenate((x_test, numpy.ones((n_test, 1))), axis=1)\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic regression model\n",
    "\n",
    "The objective function is $Q (w; X, y) = \\frac{1}{n} \\sum_{i=1}^n \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective function value\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     objective function value (scalar)\n",
    "def objective(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(-yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.log(1 + vec1) # n-by-1 matrix\n",
    "    loss = numpy.mean(vec2) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    return loss + reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial objective function value = 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "# initialize w\n",
    "d = x_train.shape[1]\n",
    "w = numpy.zeros((d, 1))\n",
    "\n",
    "# evaluate the objective function value at w\n",
    "lam = 1E-6\n",
    "objval0 = objective(w, x_train, y_train, lam)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Numerical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Gradient descent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient at $w$ is $g = - \\frac{1}{n} \\sum_{i=1}^n \\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     g: g: d-by-1 matrix, full gradient\n",
    "def gradient(w, x, y, lam):\n",
    "    n, d = x.shape\n",
    "    yx = numpy.multiply(y, x) # n-by-d matrix\n",
    "    yxw = numpy.dot(yx, w) # n-by-1 matrix\n",
    "    vec1 = numpy.exp(yxw) # n-by-1 matrix\n",
    "    vec2 = numpy.divide(yx, 1+vec1) # n-by-d matrix\n",
    "    vec3 = -numpy.mean(vec2, axis=0).reshape(d, 1) # d-by-1 matrix\n",
    "    g = vec3 + lam * w\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     objvals: a record of each iteration's objective value\n",
    "def grad_descent(x, y, lam, stepsize, max_iter=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_iter) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        objval = objective(w, x, y, lam)\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval))\n",
    "        g = gradient(w, x, y, lam)\n",
    "        w -= stepsize * g\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at t=0 is 0.6931471805599453\n",
      "Objective value at t=1 is 0.5909890373351073\n",
      "Objective value at t=2 is 0.550346134724121\n",
      "Objective value at t=3 is 0.5287801447618308\n",
      "Objective value at t=4 is 0.5154506943126274\n",
      "Objective value at t=5 is 0.5064919005181494\n",
      "Objective value at t=6 is 0.5001542337953592\n",
      "Objective value at t=7 is 0.49551464127729944\n",
      "Objective value at t=8 is 0.49203344400495436\n",
      "Objective value at t=9 is 0.4893719221491348\n",
      "Objective value at t=10 is 0.487306459481852\n",
      "Objective value at t=11 is 0.485683800358012\n",
      "Objective value at t=12 is 0.4843958402718806\n",
      "Objective value at t=13 is 0.48336454638964266\n",
      "Objective value at t=14 is 0.48253251065556124\n",
      "Objective value at t=15 is 0.48185681263321617\n",
      "Objective value at t=16 is 0.4813049143171018\n",
      "Objective value at t=17 is 0.4808518470865342\n",
      "Objective value at t=18 is 0.48047824427461017\n",
      "Objective value at t=19 is 0.4801689405608301\n",
      "Objective value at t=20 is 0.479911959175852\n",
      "Objective value at t=21 is 0.47969776922858004\n",
      "Objective value at t=22 is 0.4795187341935956\n",
      "Objective value at t=23 is 0.47936869762834333\n",
      "Objective value at t=24 is 0.4792426686954998\n",
      "Objective value at t=25 is 0.4791365811438155\n",
      "Objective value at t=26 is 0.479047106953773\n",
      "Objective value at t=27 is 0.47897151107846403\n",
      "Objective value at t=28 is 0.47890753737111463\n",
      "Objective value at t=29 is 0.47885331838772893\n",
      "Objective value at t=30 is 0.47880730361659524\n",
      "Objective value at t=31 is 0.4787682020374758\n",
      "Objective value at t=32 is 0.47873493590278526\n",
      "Objective value at t=33 is 0.4787066033645456\n",
      "Objective value at t=34 is 0.47868244811646626\n",
      "Objective value at t=35 is 0.4786618346307903\n",
      "Objective value at t=36 is 0.47864422788055827\n",
      "Objective value at t=37 is 0.4786291766754438\n",
      "Objective value at t=38 is 0.478616299921977\n",
      "Objective value at t=39 is 0.4786052752603693\n",
      "Objective value at t=40 is 0.47859582964032593\n",
      "Objective value at t=41 is 0.47858773148455497\n",
      "Objective value at t=42 is 0.47858078415672123\n",
      "Objective value at t=43 is 0.4785748205044879\n",
      "Objective value at t=44 is 0.47856969829120843\n",
      "Objective value at t=45 is 0.47856529636414874\n",
      "Objective value at t=46 is 0.47856151143471176\n",
      "Objective value at t=47 is 0.47855825536837854\n",
      "Objective value at t=48 is 0.4785554529001117\n",
      "Objective value at t=49 is 0.4785530397056176\n",
      "Objective value at t=50 is 0.47855096077081555\n",
      "Objective value at t=51 is 0.47854916901165095\n",
      "Objective value at t=52 is 0.4785476241044164\n",
      "Objective value at t=53 is 0.4785462914933635\n",
      "Objective value at t=54 is 0.47854514154784134\n",
      "Objective value at t=55 is 0.4785441488457242\n",
      "Objective value at t=56 is 0.47854329156363107\n",
      "Objective value at t=57 is 0.47854255095756665\n",
      "Objective value at t=58 is 0.4785419109202006\n",
      "Objective value at t=59 is 0.478541357603181\n",
      "Objective value at t=60 is 0.4785408790946816\n",
      "Objective value at t=61 is 0.47854046514391146\n",
      "Objective value at t=62 is 0.47854010692558396\n",
      "Objective value at t=63 is 0.47853979683841996\n",
      "Objective value at t=64 is 0.4785395283326586\n",
      "Objective value at t=65 is 0.47853929576231174\n",
      "Objective value at t=66 is 0.4785390942585411\n",
      "Objective value at t=67 is 0.4785389196210765\n",
      "Objective value at t=68 is 0.47853876822505903\n",
      "Objective value at t=69 is 0.4785386369410734\n",
      "Objective value at t=70 is 0.4785385230664703\n",
      "Objective value at t=71 is 0.47853842426635673\n",
      "Objective value at t=72 is 0.47853833852286976\n",
      "Objective value at t=73 is 0.4785382640915517\n",
      "Objective value at t=74 is 0.47853819946381454\n",
      "Objective value at t=75 is 0.47853814333463324\n",
      "Objective value at t=76 is 0.4785380945747262\n",
      "Objective value at t=77 is 0.47853805220658907\n",
      "Objective value at t=78 is 0.47853801538384255\n",
      "Objective value at t=79 is 0.47853798337342784\n",
      "Objective value at t=80 is 0.478537955540251\n",
      "Objective value at t=81 is 0.47853793133393596\n",
      "Objective value at t=82 is 0.4785379102773909\n",
      "Objective value at t=83 is 0.47853789195693813\n",
      "Objective value at t=84 is 0.4785378760137891\n",
      "Objective value at t=85 is 0.47853786213667976\n",
      "Objective value at t=86 is 0.4785378500555063\n",
      "Objective value at t=87 is 0.4785378395358228\n",
      "Objective value at t=88 is 0.47853783037408354\n",
      "Objective value at t=89 is 0.47853782239352727\n",
      "Objective value at t=90 is 0.478537815440616\n",
      "Objective value at t=91 is 0.47853780938195256\n",
      "Objective value at t=92 is 0.4785378041016119\n",
      "Objective value at t=93 is 0.47853779949883\n",
      "Objective value at t=94 is 0.4785377954860016\n",
      "Objective value at t=95 is 0.47853779198694535\n",
      "Objective value at t=96 is 0.4785377889353995\n",
      "Objective value at t=97 is 0.4785377862737191\n",
      "Objective value at t=98 is 0.4785377839517444\n",
      "Objective value at t=99 is 0.47853778192582047\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 1.0\n",
    "w, objvals_gd = grad_descent(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Stochastic gradient descent (SGD)\n",
    "\n",
    "Define $Q_i (w) = \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_i = \\frac{\\partial Q_i }{ \\partial w} = -\\frac{y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_i and the gradient of Q_i\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     lam: scalar, the regularization parameter\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def stochastic_objective_gradient(w, xi, yi, lam):\n",
    "    d = xi.shape[0]\n",
    "    yx = yi * xi # 1-by-d matrix\n",
    "    yxw = float(numpy.dot(yx, w)) # scalar\n",
    "    \n",
    "    # calculate objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # scalar\n",
    "    reg = lam / 2 * numpy.sum(w * w) # scalar\n",
    "    obj = loss + reg\n",
    "    \n",
    "    # calculate stochastic gradient\n",
    "    g_loss = -yx.T / (1 + numpy.exp(yxw)) # d-by-1 matrix\n",
    "    g = g_loss + lam * w # d-by-1 matrix\n",
    "    \n",
    "    return obj, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def sgd(x, y, lam, stepsize, max_epoch=100, w=None):\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch) # store the objective values\n",
    "    if w is None:\n",
    "        w = numpy.zeros((d, 1)) # zero initialization\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = numpy.random.permutation(n)\n",
    "        x_rand = x[rand_indices, :]\n",
    "        y_rand = y[rand_indices, :]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i, :]) # scalar\n",
    "            obj, g = stochastic_objective_gradient(w, xi, yi, lam)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.5381831443896911\n",
      "Objective value at epoch t=1 is 0.5257336555866442\n",
      "Objective value at epoch t=2 is 0.5172377899312861\n",
      "Objective value at epoch t=3 is 0.5155901911822091\n",
      "Objective value at epoch t=4 is 0.512930145689304\n",
      "Objective value at epoch t=5 is 0.5150303501936248\n",
      "Objective value at epoch t=6 is 0.508443420211133\n",
      "Objective value at epoch t=7 is 0.5049284950388931\n",
      "Objective value at epoch t=8 is 0.5056950771254358\n",
      "Objective value at epoch t=9 is 0.49968118288937335\n",
      "Objective value at epoch t=10 is 0.4988753916444388\n",
      "Objective value at epoch t=11 is 0.4968225248114389\n",
      "Objective value at epoch t=12 is 0.4927827627539867\n",
      "Objective value at epoch t=13 is 0.49538543778791083\n",
      "Objective value at epoch t=14 is 0.4927522257359338\n",
      "Objective value at epoch t=15 is 0.4912853182752106\n",
      "Objective value at epoch t=16 is 0.4915389418325325\n",
      "Objective value at epoch t=17 is 0.4880393821847628\n",
      "Objective value at epoch t=18 is 0.4893954711084912\n",
      "Objective value at epoch t=19 is 0.48714003925410615\n",
      "Objective value at epoch t=20 is 0.487015190707328\n",
      "Objective value at epoch t=21 is 0.485753266716119\n",
      "Objective value at epoch t=22 is 0.4833196745107163\n",
      "Objective value at epoch t=23 is 0.4846122230086613\n",
      "Objective value at epoch t=24 is 0.48386408967575506\n",
      "Objective value at epoch t=25 is 0.48377340796823887\n",
      "Objective value at epoch t=26 is 0.48303730906369785\n",
      "Objective value at epoch t=27 is 0.4820872661970447\n",
      "Objective value at epoch t=28 is 0.48181079587178777\n",
      "Objective value at epoch t=29 is 0.4819249444243117\n",
      "Objective value at epoch t=30 is 0.4815235788820481\n",
      "Objective value at epoch t=31 is 0.4813328400880831\n",
      "Objective value at epoch t=32 is 0.480943452639102\n",
      "Objective value at epoch t=33 is 0.48079656875369386\n",
      "Objective value at epoch t=34 is 0.48061919262162756\n",
      "Objective value at epoch t=35 is 0.48033644705333023\n",
      "Objective value at epoch t=36 is 0.4802659372197091\n",
      "Objective value at epoch t=37 is 0.4800706566842992\n",
      "Objective value at epoch t=38 is 0.47990910914149254\n",
      "Objective value at epoch t=39 is 0.4797636838734448\n",
      "Objective value at epoch t=40 is 0.4796788447261983\n",
      "Objective value at epoch t=41 is 0.4795438135975802\n",
      "Objective value at epoch t=42 is 0.4794531977672095\n",
      "Objective value at epoch t=43 is 0.4793618608526227\n",
      "Objective value at epoch t=44 is 0.4792760035939761\n",
      "Objective value at epoch t=45 is 0.4792053050379419\n",
      "Objective value at epoch t=46 is 0.47914380564165715\n",
      "Objective value at epoch t=47 is 0.4790755526848768\n",
      "Objective value at epoch t=48 is 0.4790271870425902\n",
      "Objective value at epoch t=49 is 0.47897907094213743\n",
      "Objective value at epoch t=50 is 0.47893288177257193\n",
      "Objective value at epoch t=51 is 0.47889363442014216\n",
      "Objective value at epoch t=52 is 0.4788574319231034\n",
      "Objective value at epoch t=53 is 0.4788255411111152\n",
      "Objective value at epoch t=54 is 0.4787978920084792\n",
      "Objective value at epoch t=55 is 0.47877223814147873\n",
      "Objective value at epoch t=56 is 0.47874901927501645\n",
      "Objective value at epoch t=57 is 0.47872683053888637\n",
      "Objective value at epoch t=58 is 0.478708666944007\n",
      "Objective value at epoch t=59 is 0.47869217671805275\n",
      "Objective value at epoch t=60 is 0.4786764160429221\n",
      "Objective value at epoch t=61 is 0.47866291848389625\n",
      "Objective value at epoch t=62 is 0.47865029249032187\n",
      "Objective value at epoch t=63 is 0.47863913483774095\n",
      "Objective value at epoch t=64 is 0.47862906177398284\n",
      "Objective value at epoch t=65 is 0.47861999178864867\n",
      "Objective value at epoch t=66 is 0.47861151505624655\n",
      "Objective value at epoch t=67 is 0.47860443696407284\n",
      "Objective value at epoch t=68 is 0.47859773372231446\n",
      "Objective value at epoch t=69 is 0.4785918493356419\n",
      "Objective value at epoch t=70 is 0.4785864408753235\n",
      "Objective value at epoch t=71 is 0.47858164427928945\n",
      "Objective value at epoch t=72 is 0.4785772616757262\n",
      "Objective value at epoch t=73 is 0.4785733621277184\n",
      "Objective value at epoch t=74 is 0.478569827329255\n",
      "Objective value at epoch t=75 is 0.4785666800448379\n",
      "Objective value at epoch t=76 is 0.4785638116750769\n",
      "Objective value at epoch t=77 is 0.47856125085611134\n",
      "Objective value at epoch t=78 is 0.4785589229115499\n",
      "Objective value at epoch t=79 is 0.4785568561624142\n",
      "Objective value at epoch t=80 is 0.47855497915586465\n",
      "Objective value at epoch t=81 is 0.47855328313371387\n",
      "Objective value at epoch t=82 is 0.47855177400711685\n",
      "Objective value at epoch t=83 is 0.4785504035590483\n",
      "Objective value at epoch t=84 is 0.4785491757053145\n",
      "Objective value at epoch t=85 is 0.47854806719700627\n",
      "Objective value at epoch t=86 is 0.47854707070853425\n",
      "Objective value at epoch t=87 is 0.47854617480477535\n",
      "Objective value at epoch t=88 is 0.478545367002196\n",
      "Objective value at epoch t=89 is 0.47854464053089274\n",
      "Objective value at epoch t=90 is 0.47854398669123654\n",
      "Objective value at epoch t=91 is 0.4785433978767205\n",
      "Objective value at epoch t=92 is 0.4785428685175466\n",
      "Objective value at epoch t=93 is 0.4785423918962651\n",
      "Objective value at epoch t=94 is 0.47854196271413557\n",
      "Objective value at epoch t=95 is 0.4785415762902991\n",
      "Objective value at epoch t=96 is 0.47854122907785895\n",
      "Objective value at epoch t=97 is 0.47854091619289535\n",
      "Objective value at epoch t=98 is 0.4785406345149907\n",
      "Objective value at epoch t=99 is 0.47854038125195164\n"
     ]
    }
   ],
   "source": [
    "lam = 1E-6\n",
    "stepsize = 0.1\n",
    "w, objvals_sgd = sgd(x_train, y_train, lam, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare GD with SGD\n",
    "\n",
    "Plot objective function values against epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-9b8d8f4cdfb5>:9: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:10: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:11: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.xlabel('Epochs', FontSize=20)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:12: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.ylabel('Objective Value', FontSize=20)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:13: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.xticks(FontSize=16)\n",
      "<ipython-input-16-9b8d8f4cdfb5>:14: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n",
      "  plt.yticks(FontSize=16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd = range(len(objvals_gd))\n",
    "epochs_sgd = range(len(objvals_sgd))\n",
    "\n",
    "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=4)\n",
    "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1], ['GD', 'SGD'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class label\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     X: m-by-d matrix\n",
    "# Return:\n",
    "#     f: m-by-1 matrix, the predictions\n",
    "def predict(w, X):\n",
    "    xw = numpy.dot(X, w)\n",
    "    f = numpy.sign(xw)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classification error is 0.2234375\n"
     ]
    }
   ],
   "source": [
    "# evaluate training error\n",
    "f_train = predict(w, x_train)\n",
    "diff = numpy.abs(f_train - y_train) / 2\n",
    "error_train = numpy.mean(diff)\n",
    "print('Training classification error is ' + str(error_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test classification error is 0.1796875\n"
     ]
    }
   ],
   "source": [
    "# evaluate test error\n",
    "f_test = predict(w, x_test)\n",
    "diff = numpy.abs(f_test - y_test) / 2\n",
    "error_test = numpy.mean(diff)\n",
    "print('Test classification error is ' + str(error_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Mini-batch SGD (fill the code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Compute the objective $Q_I$ and its gradient using a batch of samples\n",
    "\n",
    "Define $Q_I (w) = \\frac{1}{b} \\sum_{i \\in I} \\log \\Big( 1 + \\exp \\big( - y_i x_i^T w \\big) \\Big) + \\frac{\\lambda}{2} \\| w \\|_2^2 $, where $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_I = \\frac{\\partial Q_I }{ \\partial w} = \\frac{1}{b} \\sum_{i \\in I} \\frac{- y_i x_i }{1 + \\exp ( y_i x_i^T w)} + \\lambda w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the objective Q_I and the gradient of Q_I\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     xi: b-by-d matrix\n",
    "#     yi: b-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "# Return:\n",
    "#     obj: scalar, the objective Q_i\n",
    "#     g: d-by-1 matrix, gradient of Q_i\n",
    "def mb_stochastic_objective_gradient(w, xi, yi, lam, b):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of stochastic_objective_gradient\n",
    "    # Use matrix-vector multiplication; do not use FOR LOOP of vector-vector multiplications\n",
    "    n,d = xi.shape\n",
    "    yx = numpy.multiply(yi, xi)  # b by d matrix\n",
    "    yxw = numpy.dot(yx, w)  # b x 1 vector\n",
    "\n",
    "    # Solve objective function Q_i\n",
    "    loss = numpy.log(1 + numpy.exp(-yxw)) # b x 1 vector\n",
    "    reg = (lam / 2) * numpy.sum(w * w)  # scalar\n",
    "    obj = (1/b) * numpy.sum(loss + reg)  # scalar\n",
    "\n",
    "    # Calculate gradient\n",
    "    g_loss = numpy.multiply((1 / (1 + numpy.exp(yxw))), -yx).T + (lam + w) # d x n matrix\n",
    "    g = (1/b) * numpy.sum(g_loss, axis=1) # d x 1 vector\n",
    "    return obj, g.reshape((d,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Implement mini-batch SGD\n",
    "\n",
    "Hints:\n",
    "1. In every epoch, randomly permute the $n$ samples (just like SGD).\n",
    "2. Each epoch has $\\frac{n}{b}$ iterations. In every iteration, use $b$ samples, and compute the gradient and objective using the ``mb_stochastic_objective_gradient`` function. In the next iteration, use the next $b$ samples, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mini-Batch SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x: n-by-d matrix\n",
    "#     y: n-by-1 matrix\n",
    "#     lam: scalar, the regularization parameter\n",
    "#     b: integer, the batch size\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     objvals: record of each iteration's objective value\n",
    "def mb_sgd(x, y, lam, b, stepsize, max_epoch=100, w=None):\n",
    "    # Fill the function\n",
    "    # Follow the implementation of sgd\n",
    "    # Record one objective value per epoch (not per iteration!)\n",
    "    n, d = x.shape\n",
    "    objvals = numpy.zeros(max_epoch)\n",
    "    if not w:\n",
    "        w = numpy.zeros((d,1))\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "        iters = int(n / b)\n",
    "        indices = numpy.random.permutation(n)\n",
    "        x_rand = x[indices, :]\n",
    "        y_rand = y[indices, :]\n",
    "        start = 0\n",
    "        objval = 0\n",
    "        for i in range(iters):\n",
    "            end = start + b\n",
    "            xi = x_rand[start:end, :]\n",
    "            yi = y_rand[start:end, :]\n",
    "            obj, g = mb_stochastic_objective_gradient(w, xi, yi, lam, b)\n",
    "            objval += obj\n",
    "            w -= stepsize * g\n",
    "        \n",
    "        stepsize *= 0.9\n",
    "        objval /= n\n",
    "        objvals[t] = objval\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval))\n",
    "    \n",
    "    return w, objvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Run MB-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.060227933289472846\n",
      "Objective value at epoch t=1 is 0.06451601690161492\n",
      "Objective value at epoch t=2 is 0.07645995215023041\n",
      "Objective value at epoch t=3 is 0.05632152399920248\n",
      "Objective value at epoch t=4 is 0.05990980845808228\n",
      "Objective value at epoch t=5 is 0.07636878352915402\n",
      "Objective value at epoch t=6 is 0.06222564748614633\n",
      "Objective value at epoch t=7 is 0.047688320587989386\n",
      "Objective value at epoch t=8 is 0.07236820924446141\n",
      "Objective value at epoch t=9 is 0.05735315576098201\n",
      "Objective value at epoch t=10 is 0.07255298797037074\n",
      "Objective value at epoch t=11 is 0.07018391269175024\n",
      "Objective value at epoch t=12 is 0.07774372372908309\n",
      "Objective value at epoch t=13 is 0.06372854640602284\n",
      "Objective value at epoch t=14 is 0.08026049081474976\n",
      "Objective value at epoch t=15 is 0.06489957782346797\n",
      "Objective value at epoch t=16 is 0.05597794596009187\n",
      "Objective value at epoch t=17 is 0.07608787104785313\n",
      "Objective value at epoch t=18 is 0.06109641773500383\n",
      "Objective value at epoch t=19 is 0.06295908948194126\n",
      "Objective value at epoch t=20 is 0.06130067999343423\n",
      "Objective value at epoch t=21 is 0.07574851908419508\n",
      "Objective value at epoch t=22 is 0.06439865525408629\n",
      "Objective value at epoch t=23 is 0.06427918849606247\n",
      "Objective value at epoch t=24 is 0.07865738517055837\n",
      "Objective value at epoch t=25 is 0.07600219161727147\n",
      "Objective value at epoch t=26 is 0.06053948503647307\n",
      "Objective value at epoch t=27 is 0.058980639083284735\n",
      "Objective value at epoch t=28 is 0.07007147549607831\n",
      "Objective value at epoch t=29 is 0.06869950763219758\n",
      "Objective value at epoch t=30 is 0.06746258755004989\n",
      "Objective value at epoch t=31 is 0.08635675563757363\n",
      "Objective value at epoch t=32 is 0.0820238735969164\n",
      "Objective value at epoch t=33 is 0.07404493670929889\n",
      "Objective value at epoch t=34 is 0.08624055315749328\n",
      "Objective value at epoch t=35 is 0.08056205309548842\n",
      "Objective value at epoch t=36 is 0.08541948127001792\n",
      "Objective value at epoch t=37 is 0.07841149400959861\n",
      "Objective value at epoch t=38 is 0.08003682677867974\n",
      "Objective value at epoch t=39 is 0.07988453948892262\n",
      "Objective value at epoch t=40 is 0.07895320517567922\n",
      "Objective value at epoch t=41 is 0.07512811832053942\n",
      "Objective value at epoch t=42 is 0.07815296359637659\n",
      "Objective value at epoch t=43 is 0.07017339552583753\n",
      "Objective value at epoch t=44 is 0.07985573215802137\n",
      "Objective value at epoch t=45 is 0.07265394737386362\n",
      "Objective value at epoch t=46 is 0.07256892188405824\n",
      "Objective value at epoch t=47 is 0.08018095911130661\n",
      "Objective value at epoch t=48 is 0.07175371556477853\n",
      "Objective value at epoch t=49 is 0.0791858559942993\n",
      "Objective value at epoch t=50 is 0.07088189162616228\n",
      "Objective value at epoch t=51 is 0.07449717536665462\n",
      "Objective value at epoch t=52 is 0.06836182656849533\n",
      "Objective value at epoch t=53 is 0.07925108551767089\n",
      "Objective value at epoch t=54 is 0.07076254972591974\n",
      "Objective value at epoch t=55 is 0.07501459631357058\n",
      "Objective value at epoch t=56 is 0.06824554724922308\n",
      "Objective value at epoch t=57 is 0.07399323501964497\n",
      "Objective value at epoch t=58 is 0.07051239012971074\n",
      "Objective value at epoch t=59 is 0.07638218272229404\n",
      "Objective value at epoch t=60 is 0.08219358764896725\n",
      "Objective value at epoch t=61 is 0.07563044464974489\n",
      "Objective value at epoch t=62 is 0.0698544028476904\n",
      "Objective value at epoch t=63 is 0.07881400341175082\n",
      "Objective value at epoch t=64 is 0.08226804175193242\n",
      "Objective value at epoch t=65 is 0.08644352505288407\n",
      "Objective value at epoch t=66 is 0.07440648128762364\n",
      "Objective value at epoch t=67 is 0.08083595356226718\n",
      "Objective value at epoch t=68 is 0.08022263737207297\n",
      "Objective value at epoch t=69 is 0.08001147640401071\n",
      "Objective value at epoch t=70 is 0.08018660581368862\n",
      "Objective value at epoch t=71 is 0.07727423434005533\n",
      "Objective value at epoch t=72 is 0.08012245397604371\n",
      "Objective value at epoch t=73 is 0.08239055673723528\n",
      "Objective value at epoch t=74 is 0.07591212778815756\n",
      "Objective value at epoch t=75 is 0.07970422495639806\n",
      "Objective value at epoch t=76 is 0.06898132156341527\n",
      "Objective value at epoch t=77 is 0.08453185356837754\n",
      "Objective value at epoch t=78 is 0.07728326303884693\n",
      "Objective value at epoch t=79 is 0.08671113184551224\n",
      "Objective value at epoch t=80 is 0.08097225464350839\n",
      "Objective value at epoch t=81 is 0.07835153758217893\n",
      "Objective value at epoch t=82 is 0.08297632137064852\n",
      "Objective value at epoch t=83 is 0.08890937038250317\n",
      "Objective value at epoch t=84 is 0.07410566668311619\n",
      "Objective value at epoch t=85 is 0.07227429909350944\n",
      "Objective value at epoch t=86 is 0.07176194016103082\n",
      "Objective value at epoch t=87 is 0.0762584432445613\n",
      "Objective value at epoch t=88 is 0.0670257782441224\n",
      "Objective value at epoch t=89 is 0.074554108959864\n",
      "Objective value at epoch t=90 is 0.07418495012080163\n",
      "Objective value at epoch t=91 is 0.07854263714488936\n",
      "Objective value at epoch t=92 is 0.07602125543305294\n",
      "Objective value at epoch t=93 is 0.08018335614354448\n",
      "Objective value at epoch t=94 is 0.07242803390877156\n",
      "Objective value at epoch t=95 is 0.06598121854219212\n",
      "Objective value at epoch t=96 is 0.08032786908421165\n",
      "Objective value at epoch t=97 is 0.06733933458137716\n",
      "Objective value at epoch t=98 is 0.0785139774398209\n",
      "Objective value at epoch t=99 is 0.07898608046065643\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=8\n",
    "lam = 1E-6 # do not change\n",
    "b = 8 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd8 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value at epoch t=0 is 0.009954305836406456\n",
      "Objective value at epoch t=1 is 0.00945700013923261\n",
      "Objective value at epoch t=2 is 0.009423969880478809\n",
      "Objective value at epoch t=3 is 0.009565700658535651\n",
      "Objective value at epoch t=4 is 0.00906032366471925\n",
      "Objective value at epoch t=5 is 0.009540827044098811\n",
      "Objective value at epoch t=6 is 0.009531823174797782\n",
      "Objective value at epoch t=7 is 0.00941750512244654\n",
      "Objective value at epoch t=8 is 0.00959274958760441\n",
      "Objective value at epoch t=9 is 0.009088879294258384\n",
      "Objective value at epoch t=10 is 0.010001582346208689\n",
      "Objective value at epoch t=11 is 0.00951420141675706\n",
      "Objective value at epoch t=12 is 0.009572020392812627\n",
      "Objective value at epoch t=13 is 0.009658955947875924\n",
      "Objective value at epoch t=14 is 0.010119866107762155\n",
      "Objective value at epoch t=15 is 0.009832081374068042\n",
      "Objective value at epoch t=16 is 0.009293773583911756\n",
      "Objective value at epoch t=17 is 0.009422398930882508\n",
      "Objective value at epoch t=18 is 0.009485306198467238\n",
      "Objective value at epoch t=19 is 0.009667970724024429\n",
      "Objective value at epoch t=20 is 0.009568660990629493\n",
      "Objective value at epoch t=21 is 0.009166709782241643\n",
      "Objective value at epoch t=22 is 0.009180706623251171\n",
      "Objective value at epoch t=23 is 0.010061509960326714\n",
      "Objective value at epoch t=24 is 0.009719392855488626\n",
      "Objective value at epoch t=25 is 0.009391691839833566\n",
      "Objective value at epoch t=26 is 0.00950036408631013\n",
      "Objective value at epoch t=27 is 0.009392151775523088\n",
      "Objective value at epoch t=28 is 0.009636593839935006\n",
      "Objective value at epoch t=29 is 0.009536470576033901\n",
      "Objective value at epoch t=30 is 0.009162843999807026\n",
      "Objective value at epoch t=31 is 0.009253266139773175\n",
      "Objective value at epoch t=32 is 0.009766342572128234\n",
      "Objective value at epoch t=33 is 0.009886769901606602\n",
      "Objective value at epoch t=34 is 0.009583301463761226\n",
      "Objective value at epoch t=35 is 0.010068092600157246\n",
      "Objective value at epoch t=36 is 0.00905778875473237\n",
      "Objective value at epoch t=37 is 0.009596986507052799\n",
      "Objective value at epoch t=38 is 0.009329625862173119\n",
      "Objective value at epoch t=39 is 0.010265362839935382\n",
      "Objective value at epoch t=40 is 0.00981413837444627\n",
      "Objective value at epoch t=41 is 0.0095915783648909\n",
      "Objective value at epoch t=42 is 0.009805401899353541\n",
      "Objective value at epoch t=43 is 0.009115930740929012\n",
      "Objective value at epoch t=44 is 0.009143578315280176\n",
      "Objective value at epoch t=45 is 0.009394630750461274\n",
      "Objective value at epoch t=46 is 0.009437106641153487\n",
      "Objective value at epoch t=47 is 0.009695218885102792\n",
      "Objective value at epoch t=48 is 0.00954326793929032\n",
      "Objective value at epoch t=49 is 0.009879636824384735\n",
      "Objective value at epoch t=50 is 0.009824602013466464\n",
      "Objective value at epoch t=51 is 0.009731108745337206\n",
      "Objective value at epoch t=52 is 0.009784291816518366\n",
      "Objective value at epoch t=53 is 0.009378525280474455\n",
      "Objective value at epoch t=54 is 0.009639403548525256\n",
      "Objective value at epoch t=55 is 0.009482807268005216\n",
      "Objective value at epoch t=56 is 0.009683238489731717\n",
      "Objective value at epoch t=57 is 0.009920520375330057\n",
      "Objective value at epoch t=58 is 0.009832113313101425\n",
      "Objective value at epoch t=59 is 0.009904957199209034\n",
      "Objective value at epoch t=60 is 0.00951674453680881\n",
      "Objective value at epoch t=61 is 0.00973957125737\n",
      "Objective value at epoch t=62 is 0.009273628616818234\n",
      "Objective value at epoch t=63 is 0.009812408311161395\n",
      "Objective value at epoch t=64 is 0.009425856042384991\n",
      "Objective value at epoch t=65 is 0.009508151224239753\n",
      "Objective value at epoch t=66 is 0.009493226305765753\n",
      "Objective value at epoch t=67 is 0.009796960183678375\n",
      "Objective value at epoch t=68 is 0.009615980086974635\n",
      "Objective value at epoch t=69 is 0.009536760270518276\n",
      "Objective value at epoch t=70 is 0.009716346158791718\n",
      "Objective value at epoch t=71 is 0.009242969917686663\n",
      "Objective value at epoch t=72 is 0.009610481183623605\n",
      "Objective value at epoch t=73 is 0.009829903204902948\n",
      "Objective value at epoch t=74 is 0.009782658589543821\n",
      "Objective value at epoch t=75 is 0.009808814378337237\n",
      "Objective value at epoch t=76 is 0.009274363793126452\n",
      "Objective value at epoch t=77 is 0.009347889641221718\n",
      "Objective value at epoch t=78 is 0.009901561776977716\n",
      "Objective value at epoch t=79 is 0.009778667328389222\n",
      "Objective value at epoch t=80 is 0.009552687824932782\n",
      "Objective value at epoch t=81 is 0.009532007383776433\n",
      "Objective value at epoch t=82 is 0.009919482102927445\n",
      "Objective value at epoch t=83 is 0.0094913889315772\n",
      "Objective value at epoch t=84 is 0.009621908546410571\n",
      "Objective value at epoch t=85 is 0.009668020345757287\n",
      "Objective value at epoch t=86 is 0.009815527915299537\n",
      "Objective value at epoch t=87 is 0.009559356135195863\n",
      "Objective value at epoch t=88 is 0.009748028662092883\n",
      "Objective value at epoch t=89 is 0.00993793347317355\n",
      "Objective value at epoch t=90 is 0.009770244190045452\n",
      "Objective value at epoch t=91 is 0.010112301953397226\n",
      "Objective value at epoch t=92 is 0.00966859881372001\n",
      "Objective value at epoch t=93 is 0.009827207497712168\n",
      "Objective value at epoch t=94 is 0.00933417086338666\n",
      "Objective value at epoch t=95 is 0.009288183522078348\n",
      "Objective value at epoch t=96 is 0.009610038329467507\n",
      "Objective value at epoch t=97 is 0.009576168417667764\n",
      "Objective value at epoch t=98 is 0.009637430605324845\n",
      "Objective value at epoch t=99 is 0.009311938506829593\n"
     ]
    }
   ],
   "source": [
    "# MB-SGD with batch size b=64\n",
    "lam = 1E-6 # do not change\n",
    "b = 64 # do not change\n",
    "stepsize = 0.1 # you must tune this parameter\n",
    "\n",
    "w, objvals_mbsgd64 = mb_sgd(x_train, y_train, lam, b, stepsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Plot and compare GD, SGD, and MB-SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are required to compare the following algorithms:\n",
    "\n",
    "- Gradient descent (GD)\n",
    "\n",
    "- SGD\n",
    "\n",
    "- MB-SGD with b=8\n",
    "\n",
    "- MB-SGD with b=64\n",
    "\n",
    "Follow the code in Section 4 to plot ```objective function value``` against ```epochs```. There should be four curves in the plot; each curve corresponds to one algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: Logistic regression with $\\ell_2$-norm regularization is a strongly convex optimization problem. All the algorithms will converge to the same solution. **In the end, the ``objective function value`` of the 4 algorithms will be the same. If not the same, your implementation must be wrong. Do NOT submit wrong code and wrong result!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 4 curves:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
